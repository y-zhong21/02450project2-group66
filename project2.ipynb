{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from dtuimldmtools import bmplot, feature_selector_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# define data file name\n",
    "data_file = \"../project1_data/Rice_Cammeo_Osmancik.csv\"\n",
    "\n",
    "#load data\n",
    "data = pd.read_csv(data_file)\n",
    "\n",
    "# Check missing values\n",
    "missing_values = data.isnull().values.any()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Major_Axis_Length</th>\n",
       "      <th>Minor_Axis_Length</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Convex_Area</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15231.0</td>\n",
       "      <td>525.578979</td>\n",
       "      <td>229.749878</td>\n",
       "      <td>85.093788</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>15617.0</td>\n",
       "      <td>0.572896</td>\n",
       "      <td>b'Cammeo'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14656.0</td>\n",
       "      <td>494.311005</td>\n",
       "      <td>206.020065</td>\n",
       "      <td>91.730972</td>\n",
       "      <td>0.895405</td>\n",
       "      <td>15072.0</td>\n",
       "      <td>0.615436</td>\n",
       "      <td>b'Cammeo'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14634.0</td>\n",
       "      <td>501.122009</td>\n",
       "      <td>214.106781</td>\n",
       "      <td>87.768288</td>\n",
       "      <td>0.912118</td>\n",
       "      <td>14954.0</td>\n",
       "      <td>0.693259</td>\n",
       "      <td>b'Cammeo'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13176.0</td>\n",
       "      <td>458.342987</td>\n",
       "      <td>193.337387</td>\n",
       "      <td>87.448395</td>\n",
       "      <td>0.891861</td>\n",
       "      <td>13368.0</td>\n",
       "      <td>0.640669</td>\n",
       "      <td>b'Cammeo'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14688.0</td>\n",
       "      <td>507.166992</td>\n",
       "      <td>211.743378</td>\n",
       "      <td>89.312454</td>\n",
       "      <td>0.906691</td>\n",
       "      <td>15262.0</td>\n",
       "      <td>0.646024</td>\n",
       "      <td>b'Cammeo'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Area   Perimeter  Major_Axis_Length  Minor_Axis_Length  Eccentricity  \\\n",
       "0  15231.0  525.578979         229.749878          85.093788      0.928882   \n",
       "1  14656.0  494.311005         206.020065          91.730972      0.895405   \n",
       "2  14634.0  501.122009         214.106781          87.768288      0.912118   \n",
       "3  13176.0  458.342987         193.337387          87.448395      0.891861   \n",
       "4  14688.0  507.166992         211.743378          89.312454      0.906691   \n",
       "\n",
       "   Convex_Area    Extent      Class  \n",
       "0      15617.0  0.572896  b'Cammeo'  \n",
       "1      15072.0  0.615436  b'Cammeo'  \n",
       "2      14954.0  0.693259  b'Cammeo'  \n",
       "3      13368.0  0.640669  b'Cammeo'  \n",
       "4      15262.0  0.646024  b'Cammeo'  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Major_Axis_Length</th>\n",
       "      <th>Minor_Axis_Length</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Convex_Area</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Class_b'Osmancik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15231.0</td>\n",
       "      <td>525.578979</td>\n",
       "      <td>229.749878</td>\n",
       "      <td>85.093788</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>15617.0</td>\n",
       "      <td>0.572896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14656.0</td>\n",
       "      <td>494.311005</td>\n",
       "      <td>206.020065</td>\n",
       "      <td>91.730972</td>\n",
       "      <td>0.895405</td>\n",
       "      <td>15072.0</td>\n",
       "      <td>0.615436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14634.0</td>\n",
       "      <td>501.122009</td>\n",
       "      <td>214.106781</td>\n",
       "      <td>87.768288</td>\n",
       "      <td>0.912118</td>\n",
       "      <td>14954.0</td>\n",
       "      <td>0.693259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13176.0</td>\n",
       "      <td>458.342987</td>\n",
       "      <td>193.337387</td>\n",
       "      <td>87.448395</td>\n",
       "      <td>0.891861</td>\n",
       "      <td>13368.0</td>\n",
       "      <td>0.640669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14688.0</td>\n",
       "      <td>507.166992</td>\n",
       "      <td>211.743378</td>\n",
       "      <td>89.312454</td>\n",
       "      <td>0.906691</td>\n",
       "      <td>15262.0</td>\n",
       "      <td>0.646024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Area   Perimeter  Major_Axis_Length  Minor_Axis_Length  Eccentricity  \\\n",
       "0  15231.0  525.578979         229.749878          85.093788      0.928882   \n",
       "1  14656.0  494.311005         206.020065          91.730972      0.895405   \n",
       "2  14634.0  501.122009         214.106781          87.768288      0.912118   \n",
       "3  13176.0  458.342987         193.337387          87.448395      0.891861   \n",
       "4  14688.0  507.166992         211.743378          89.312454      0.906691   \n",
       "\n",
       "   Convex_Area    Extent  Class_b'Osmancik  \n",
       "0      15617.0  0.572896                 0  \n",
       "1      15072.0  0.615436                 0  \n",
       "2      14954.0  0.693259                 0  \n",
       "3      13368.0  0.640669                 0  \n",
       "4      15262.0  0.646024                 0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use other features to predict the eccenctricity\n",
    "# by predicting some parameters describing the rice grains' shape and size, we can get a deeper understanding of the rice grains' quality\n",
    "# do 1-out-of-K encoding for the categorical feature \"Class\" to transform it into a numerical feature\n",
    "data = pd.get_dummies(data, columns=[\"Class\"], drop_first=True)\n",
    "# transform True/False to 1/0 (categorical feature \"Class_b'Osmancik\")\n",
    "data[\"Class_b'Osmancik\"] = data[\"Class_b'Osmancik'\"].astype(int)\n",
    "data = data.drop(columns=[\"Class_b'Osmancik'\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means Area                 12667.727559\n",
      "Perimeter              454.239180\n",
      "Major_Axis_Length      188.776222\n",
      "Minor_Axis_Length       86.313750\n",
      "Convex_Area          12952.496850\n",
      "Extent                   0.661934\n",
      "dtype: float64\n",
      "vars Area                 1732.367706\n",
      "Perimeter              35.597081\n",
      "Major_Axis_Length      17.448679\n",
      "Minor_Axis_Length       5.729817\n",
      "Convex_Area          1776.972042\n",
      "Extent                  0.077239\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Major_Axis_Length</th>\n",
       "      <th>Minor_Axis_Length</th>\n",
       "      <th>Convex_Area</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Class_b'Osmancik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.479635</td>\n",
       "      <td>2.004091</td>\n",
       "      <td>2.348238</td>\n",
       "      <td>-0.212915</td>\n",
       "      <td>1.499463</td>\n",
       "      <td>-1.152770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.147720</td>\n",
       "      <td>1.125705</td>\n",
       "      <td>0.988261</td>\n",
       "      <td>0.945444</td>\n",
       "      <td>1.192761</td>\n",
       "      <td>-0.602000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.135020</td>\n",
       "      <td>1.317041</td>\n",
       "      <td>1.451718</td>\n",
       "      <td>0.253854</td>\n",
       "      <td>1.126356</td>\n",
       "      <td>0.405558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.293398</td>\n",
       "      <td>0.115285</td>\n",
       "      <td>0.261405</td>\n",
       "      <td>0.198025</td>\n",
       "      <td>0.233826</td>\n",
       "      <td>-0.275315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.166191</td>\n",
       "      <td>1.486858</td>\n",
       "      <td>1.316269</td>\n",
       "      <td>0.523351</td>\n",
       "      <td>1.299685</td>\n",
       "      <td>-0.205986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Area  Perimeter  Major_Axis_Length  Minor_Axis_Length  Convex_Area  \\\n",
       "0  1.479635   2.004091           2.348238          -0.212915     1.499463   \n",
       "1  1.147720   1.125705           0.988261           0.945444     1.192761   \n",
       "2  1.135020   1.317041           1.451718           0.253854     1.126356   \n",
       "3  0.293398   0.115285           0.261405           0.198025     0.233826   \n",
       "4  1.166191   1.486858           1.316269           0.523351     1.299685   \n",
       "\n",
       "     Extent  Class_b'Osmancik  \n",
       "0 -1.152770                 0  \n",
       "1 -0.602000                 0  \n",
       "2  0.405558                 0  \n",
       "3 -0.275315                 0  \n",
       "4 -0.205986                 0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply a feature transformation to your data matrix X such that each column has mean 0 and standard deviation 1, except for categorical features\n",
    "# get the known features\n",
    "X = data.drop(columns=[\"Eccentricity\"])\n",
    "X_transformed = X.iloc[:, :-1]\n",
    "# record the means and vars\n",
    "means = X_transformed.mean()\n",
    "vars = X_transformed.std()\n",
    "# apply the transformation\n",
    "X_transformed = (X_transformed - X_transformed.mean()) / X_transformed.std()\n",
    "X = pd.concat([X_transformed, X.iloc[:,-1]], axis=1)\n",
    "# define the target variable\n",
    "y = data[\"Eccentricity\"]\n",
    "# show results\n",
    "print('means',means)\n",
    "print('vars',vars)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem I have chosen to address is a binary classification task.  The 'Class' column within the dataset serves as the target variable, distinguishing between two distinct categories of rice, 'Cammeo' and 'Osmancik'. Consequently, each rice grain instance is categorized as either 'Cammeo' or 'Osmancik', establishing the binary nature of this classification challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "le = LabelEncoder()\n",
    "data['Class_encoded'] = le.fit_transform(data['Class'])\n",
    "X = data.drop(['Class', 'Class_encoded'], axis=1)\n",
    "y = data['Class_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation and definition of parameter grid for Logistic Regression\n",
    "log_reg = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "param_grid = {'C': [0.02, 0.04, 0.06, 0.08, 0.1, 0.12, 0.14, 0.16, 0.18]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 0.06}\n",
      "Best cross-validation score: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Fit GridSearchCV to training data to find the best Logistic Regression model\n",
    "grid_search = GridSearchCV(log_reg, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation and definition of parameter grid for KNN\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': list(range(1, 15))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'n_neighbors': 7}\n",
      "Best cross-validation score: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Fit GridSearchCV to training data to find the best KNN model\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For logistic regression, the complexity-controlling parameter λ, which is inversely related to the parameter 'C', is chosen as 50/3 (C=0.06). This value has been selected from a range: [0.02, 0.04, 0.06, 0.08, 0.1, 0.12, 0.14, 0.16, 0.18]. This implies that we expect some regularization to prevent overfitting while retaining the model's capacity to capture the underlying patterns in the data.\n",
    "\n",
    "For the KNN algorithm, the complexity is controlled by the number of neighbors, k, which has been selected as 7. This parameter was chosen from a smaller, more targeted range: [1, 15]. A k value of 7 strikes a balance, aiming to ensure that the model generalizes well to new data without being overly complex or too simplistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for cross-validation\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "outer_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Outer fold  Method 2  Etest_Method2  Logistic regression  Etest_LogReg  \\\n",
      "0           1         3      11.286089                 0.04      6.561680   \n",
      "1           2         3       8.923885                 0.04      7.349081   \n",
      "2           3         3       9.448819                 0.06      6.561680   \n",
      "3           4         3      11.023622                 0.04      6.561680   \n",
      "4           5         3      12.073491                 0.10      8.661417   \n",
      "5           6         3      12.335958                 0.08      6.824147   \n",
      "6           7         3      11.023622                 0.10      7.086614   \n",
      "7           8         3      12.335958                 0.12      7.611549   \n",
      "8           9         3      11.811024                 0.12      7.874016   \n",
      "9          10         3      12.860892                 0.18      4.986877   \n",
      "\n",
      "   Etest_Baseline  \n",
      "0       42.782152  \n",
      "1       42.782152  \n",
      "2       42.782152  \n",
      "3       42.782152  \n",
      "4       42.782152  \n",
      "5       42.782152  \n",
      "6       42.782152  \n",
      "7       42.782152  \n",
      "8       42.782152  \n",
      "9       42.782152  \n"
     ]
    }
   ],
   "source": [
    "# Define the baseline error rate function\n",
    "def baseline_error_rate(y_true, y_pred):\n",
    "    return np.sum(y_pred != y_true) / len(y_true)\n",
    "\n",
    "# Conduct cross-validation with grid search for Logistic Regression and KNN\n",
    "for i, (train_index, test_index) in enumerate(outer_cv.split(X, y), start=1):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Logistic Regression with Grid Search\n",
    "    log_reg = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "    param_grid_log_reg = {'C': [0.02, 0.04, 0.06, 0.08, 0.1, 0.12, 0.14, 0.16, 0.18]}\n",
    "    grid_search_log_reg = GridSearchCV(log_reg, param_grid_log_reg, cv=5)\n",
    "    grid_search_log_reg.fit(X_train, y_train)\n",
    "    \n",
    "    # KNN with Grid Search\n",
    "    knn = KNeighborsClassifier()\n",
    "    param_grid_knn = {'n_neighbors': list(range(1, 15))}\n",
    "    grid_search_knn = GridSearchCV(knn, param_grid_knn, cv=5)\n",
    "    grid_search_knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate models\n",
    "    best_log_reg = grid_search_log_reg.best_estimator_\n",
    "    best_log_reg.fit(X_train, y_train)\n",
    "    y_pred_log_reg = best_log_reg.predict(X_test)\n",
    "    \n",
    "    best_knn = grid_search_knn.best_estimator_\n",
    "    best_knn.fit(X_train, y_train)\n",
    "    y_pred_knn = best_knn.predict(X_test)\n",
    "    \n",
    "    baseline_pred = np.full_like(y_test, y_train.value_counts().idxmax())\n",
    "    \n",
    "    # Calculate error rates\n",
    "    error_rate_log_reg = baseline_error_rate(y_test, y_pred_log_reg)\n",
    "    error_rate_knn = baseline_error_rate(y_test, y_pred_knn)\n",
    "    error_rate_baseline = baseline_error_rate(y_test, baseline_pred)\n",
    "    \n",
    "    # Append results\n",
    "    outer_results.append({\n",
    "        'Outer fold': i,\n",
    "        'Method 2': grid_search_knn.best_params_['n_neighbors'],\n",
    "        'Etest_Method2': error_rate_knn * 100,\n",
    "        'Logistic regression': grid_search_log_reg.best_params_['C'],\n",
    "        'Etest_LogReg': error_rate_log_reg * 100,\n",
    "        'Etest_Baseline': error_rate_baseline * 100\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(outer_results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform statistical analysis\n",
    "t_statistic_lr_vs_knn, p_value_lr_vs_knn = stats.ttest_rel(results_df['Etest_LogReg'], results_df['Etest_Method2'])\n",
    "t_statistic_lr_vs_baseline, p_value_lr_vs_baseline = stats.ttest_rel(results_df['Etest_LogReg'], results_df['Etest_Baseline'])\n",
    "t_statistic_knn_vs_baseline, p_value_knn_vs_baseline = stats.ttest_rel(results_df['Etest_Method2'], results_df['Etest_Baseline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confidence intervals\n",
    "confidence_interval_lr_vs_knn = stats.t.interval(0.95, len(results_df['Etest_LogReg'])-1, loc=np.mean(results_df['Etest_LogReg']-results_df['Etest_Method2']), scale=stats.sem(results_df['Etest_LogReg']-results_df['Etest_Method2']))\n",
    "confidence_interval_lr_vs_baseline = stats.t.interval(0.95, len(results_df['Etest_LogReg'])-1, loc=np.mean(results_df['Etest_LogReg']-results_df['Etest_Baseline']), scale=stats.sem(results_df['Etest_LogReg']-results_df['Etest_Baseline']))\n",
    "confidence_interval_knn_vs_baseline = stats.t.interval(0.95, len(results_df['Etest_Method2'])-1, loc=np.mean(results_df['Etest_Method2']-results_df['Etest_Baseline']), scale=stats.sem(results_df['Etest_Method2']-results_df['Etest_Baseline']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR vs. KNN: p-value = 1.9069615482306397e-05, CI = (-5.499180825091497, -3.1097430594229385)\n",
      "LR vs. Baseline: p-value = 1.4266885777241929e-15, CI = (-36.47708199255887, -35.071474437887325)\n",
      "KNN vs. Baseline: p-value = 4.759574858916058e-14, CI = (-32.38301305924021, -30.556619486691545)\n"
     ]
    }
   ],
   "source": [
    "# Print statistical analysis results\n",
    "print(f\"LR vs. KNN: p-value = {p_value_lr_vs_knn}, CI = {confidence_interval_lr_vs_knn}\")\n",
    "print(f\"LR vs. Baseline: p-value = {p_value_lr_vs_baseline}, CI = {confidence_interval_lr_vs_baseline}\")\n",
    "print(f\"KNN vs. Baseline: p-value = {p_value_knn_vs_baseline}, CI = {confidence_interval_knn_vs_baseline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is one model better than the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is approximately 0.0000197, which is approximatel less than 0.05, indicating a statistically significant improvement of the logistic regression model over the KNN. The confidence interval for the difference is also far from including 0, confirming the improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the two models better than the baseline?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR vs. Baseline: The p-value is approximately 1.43e-15, which is much less than 0.05, indicating a statistically significant improvement of the logistic regression model over the baseline. The confidence interval for the difference is also far from including 0, confirming the improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN vs. Baseline: The p-value is approximately 4.76e-14, which is much less than 0.05, indicating a statistically significant improvement of the KNN model over the baseline. The confidence interval for the difference is also far from including 0, confirming the improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are some of the models identical?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the significant p-values when comparing both models to the baseline and each other, we can conclude that none of the models are identical in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What recommendations would you make based on what you’ve learned?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection of Model: The statistical evidence suggests that both the logistic regression and KNN models are significantly better than the baseline model, with one of them also being significantly better than the other. The specific choice between logistic regression and KNN should be based on which model had the lower error rate in the pairwise comparison, which the confidence interval suggests is the logistic regression model.\n",
    "\n",
    "Model Deployment: Given the results, I would recommend deploying the logistic regression model for this particular dataset, as it not only outperforms the baseline but also the KNN model.\n",
    "\n",
    "Further Analysis: Despite the statistical significance, the practical significance should also be evaluated. If the performance improvement is marginal, it may not justify the costs of changing models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Feature  Importance\n",
      "3  Minor_Axis_Length    0.376948\n",
      "1          Perimeter    0.138839\n",
      "0               Area    0.007600\n",
      "6             Extent    0.003147\n",
      "4       Eccentricity    0.001394\n",
      "5        Convex_Area   -0.011414\n",
      "2  Major_Axis_Length   -0.230331\n"
     ]
    }
   ],
   "source": [
    "# Train the logistic regression model using the best value of λ\n",
    "for i, (train_index, test_index) in enumerate(outer_cv.split(X, y), start=1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    log_reg = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "    param_grid_log_reg = {'C': [0.02, 0.04, 0.06, 0.08, 0.1, 0.12, 0.14, 0.16, 0.18]}\n",
    "    grid_search_log_reg = GridSearchCV(log_reg, param_grid_log_reg, cv=5)\n",
    "    grid_search_log_reg.fit(X_train, y_train)\n",
    "    \n",
    "    best_log_reg = grid_search_log_reg.best_estimator_\n",
    "    y_pred_log_reg = best_log_reg.predict(X_test)\n",
    "    \n",
    "    error_rate_log_reg = baseline_error_rate(y_test, y_pred_log_reg)\n",
    "    \n",
    "    outer_results.append({\n",
    "        'Outer fold': i,\n",
    "        'Logistic regression C': grid_search_log_reg.best_params_['C'],\n",
    "        'Etest_LogReg': error_rate_log_reg * 100,\n",
    "    })\n",
    "\n",
    "# Examining feature importance for Logistic Regression\n",
    "feature_importance = pd.DataFrame(data={'Feature': X.columns, 'Importance': best_log_reg.coef_[0]})\n",
    "print(feature_importance.sort_values(by='Importance', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Logistic Regression Makes Predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It uses the sigmoid function to squeeze the output of a linear equation between 0 and 1. The model coefficients indicate the relationship between each feature and the log odds of the dependent variable, allowing the prediction of probabilities that are then mapped to class labels based on a threshold (commonly 0.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the same features deemed relevant as for the regression part of the report?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldtu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
